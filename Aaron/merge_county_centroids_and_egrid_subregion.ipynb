{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script reads a shapefile of US Counties provided by the NWS (https://www.weather.gov/gis/Counties), extracts the longitude and latitude of the centroid of each county, rounds to the nearest 0.25 degree (to be compatible with the ERA5 data set) and also includes the predictors:\n",
    "- State\n",
    "- CWA (County Warning Area)\n",
    "- County Name\n",
    "- FIPS (the official county code)\n",
    "- FE_Area (the area of the state in which each county is situated)\n",
    "\n",
    "*Note that I'm going to assume that the counties (names, FIPS, centroid) have not changed since 2014.*\n",
    "\n",
    "Then the script loads information about the energy grid for each county provided by the EPA (https://www.epa.gov/egrid/egrid-mapping-files) and identifies which grid sub-region the county centroid lies in.\n",
    "\n",
    "*We have egrid data for most years back to 2014; if a year is missing data, I'll use data from the previous year*\n",
    "\n",
    "Then the script loads the NRI Hazard Info (https://hazards.fema.gov/nri/data-resources#hdrDownload) and merges the following predictors into the list of counties:\n",
    "- Population\n",
    "- Value of buildings\n",
    "- Value of agriculture\n",
    "- Area\n",
    "- Social Vulnerability Score\n",
    "- Risks from: Avalange, Costal Flodding, Cold Wave, Hail, Heat Wave, Hurricane, Ice Storm, Landslide, Lightning, Riverine Flooding, Strong Wind, Tornado, Tsunami, Wildfire, and Winter Weather\n",
    "\n",
    "*Note that there isn't much historical data available - only for 2023, November 2021, August 2021, and October 2020. I'll use the 2023 data for 2023, November 2021 data for 2021 and 2022, and October 2020 data for 2020 and all previous years.*\n",
    "\n",
    "Then the script loads data from HHS emPOWER (https://empowerprogram.hhs.gov/about-empowermap.html), computes yearly means by county, and merges this data. \n",
    "\n",
    "*Note that we have yearly empower data since 2016. I'll use the 2016 data for 2014 and 2015.*\n",
    "\n",
    "Finally, the script exports the dataframe for each year as a separate CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll load and feature-reduce the list of counties from NWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the NWS US Counties shapefile\n",
    "counties = geopandas.read_file('../Data/NWS_US_Counties_Shapefiles')\n",
    "\n",
    "#Remove the geometry, and time zone variables\n",
    "counties = counties.drop(columns=['geometry', 'TIME_ZONE'])\n",
    "\n",
    "#Restrict data to the continental US: Remove all entries in counties where STATE is AS, PR, VI, PW, MH, MP, GU, HI, AK, or FM\n",
    "counties = counties[~counties['STATE'].isin(['AS', 'PR', 'VI', 'PW', 'MH', 'MP', 'GU', 'FM', 'HI', 'AK'])]\n",
    "\n",
    "#Convert FIPS in counties to float64 (to facilitate merging with other data sets)\n",
    "counties['FIPS'] = counties['FIPS'].astype(float)\n",
    "\n",
    "#Create a new point series in counties using LON as the x coordinate and LAT as the y coordinate\n",
    "counties['centroid'] = geopandas.points_from_xy(counties['LON'], counties['LAT'])\n",
    "\n",
    "#Convert counties into a geodataframe and set its crs\n",
    "counties = geopandas.GeoDataFrame(counties, geometry='centroid')\n",
    "counties.crs=\"EPSG:4326\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll load the egrid data. The EPA used slightly different file naming conventions for each year, so we'll need to specify the filenames manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the egrid subregions shapefiles, specify the CRS, and rename columns for consistency\n",
    "egrid2023 = geopandas.read_file('../Data/egrid2023_subregions')\n",
    "egrid2023 = egrid2023.to_crs(\"EPSG:4326\")\n",
    "\n",
    "egrid2022 = geopandas.read_file('../Data/egrid2022_subregions_shapefile')\n",
    "egrid2022 = egrid2022.to_crs(\"EPSG:4326\")\n",
    "egrid2022.rename(columns={'ZipSubregi': 'Subregion'}, inplace=True)\n",
    "\n",
    "egrid2021 = geopandas.read_file('../Data/eGRID2021_subregions_shapefile')\n",
    "egrid2021 = egrid2021.to_crs(\"EPSG:4326\")\n",
    "egrid2021.rename(columns={'Shape__Are': 'Shape_Area', 'Shape__Len': 'Shape_Leng', 'SUBRGN': 'Subregion'}, inplace=True)\n",
    "\n",
    "egrid2020 = geopandas.read_file('../Data/egrid2020_subregions')\n",
    "egrid2020 = egrid2020.to_crs(\"EPSG:4326\")\n",
    "egrid2020.rename(columns={'ZipSubregi': 'Subregion'}, inplace=True)\n",
    "egrid2020.drop(columns=['Shape_Le_1'], inplace=True)\n",
    "\n",
    "egrid2019 = geopandas.read_file('../Data/egrid2019_subregions')\n",
    "egrid2019 = egrid2019.to_crs(\"EPSG:4326\")\n",
    "egrid2019.rename(columns={'ZipSubregi': 'Subregion'}, inplace=True)\n",
    "egrid2019.drop(columns=['Shape_Le_1'], inplace=True)\n",
    "\n",
    "egrid2018 = geopandas.read_file('../Data/egrid2018_subregions')\n",
    "egrid2018 = egrid2018.to_crs(\"EPSG:4326\")\n",
    "egrid2018.rename(columns={'ZipSubregi': 'Subregion'}, inplace=True)\n",
    "\n",
    "egrid2016 = geopandas.read_file('../Data/egrid_2016_subregions_shapefiles')\n",
    "egrid2016 = egrid2016.to_crs(\"EPSG:4326\")\n",
    "egrid2016.rename(columns={'Subregions': 'Subregion'}, inplace=True)\n",
    "egrid2016['Shape_Leng'] = ''\n",
    "egrid2016['Shape_Area'] = ''\n",
    "\n",
    "egrid2014 = geopandas.read_file('../Data/egrid_subregions')\n",
    "egrid2014 = egrid2014.to_crs(\"EPSG:4326\")\n",
    "egrid2014.rename(columns={'zips_for_G': 'Subregion'}, inplace=True)\n",
    "egrid2014['Shape_Leng'] = ''\n",
    "egrid2014['Shape_Area'] = ''\n",
    "\n",
    "#Create a list of egrid files\n",
    "egrid_files = [egrid2023, egrid2022, egrid2021, egrid2020, egrid2019, egrid2018, egrid2016, egrid2014]\n",
    "\n",
    "#Drop the variables Shape_Leng and Shape_Area from each of the files in egrid_files\n",
    "for egrid in egrid_files:\n",
    "    egrid.drop(columns=['Shape_Leng', 'Shape_Area'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll merge the counties and egrid dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sjoin from geopandas.tools to identify which point value from counties_merged is contained within each multipolygon from the geometry variable in egrid\n",
    "from geopandas.tools import sjoin\n",
    "\n",
    "counties2023 = sjoin(counties, egrid2023, how='left')\n",
    "counties2022 = sjoin(counties, egrid2022, how='left')\n",
    "counties2021 = sjoin(counties, egrid2021, how='left')\n",
    "counties2020 = sjoin(counties, egrid2020, how='left')\n",
    "counties2019 = sjoin(counties, egrid2019, how='left')\n",
    "counties2018 = sjoin(counties, egrid2018, how='left')\n",
    "counties2017 = sjoin(counties, egrid2016, how='left')\n",
    "counties2016 = sjoin(counties, egrid2016, how='left')\n",
    "counties2015 = sjoin(counties, egrid2014, how='left')\n",
    "counties2014 = sjoin(counties, egrid2014, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A manual check revealed several FIPS codes that weren't automatically mapped to an eGRID subregion.\n",
    "\n",
    "I searched for the county name to identify associated ZIP codes, then entered those into the EPA power profiler (https://www.epa.gov/egrid/power-profiler) to identify the eGRID subregion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In all of the counties files, change the missing subregions to the eGRID subregion looked up online\n",
    "counties_files = [counties2023, counties2022, counties2021, counties2020, counties2019, counties2018, counties2017, counties2016, counties2015, counties2014]\n",
    "\n",
    "for counties in counties_files:\n",
    "    counties.loc[counties['FIPS'] == 44005.0, 'Subregion'] = 'NEWE'\n",
    "    counties.loc[counties['FIPS'] == 45043.0, 'Subregion'] = 'SRVC'\n",
    "    counties.loc[counties['FIPS'] == 26083.0, 'Subregion'] = 'MROE'\n",
    "    counties.loc[counties['FIPS'] == 12087.0, 'Subregion'] = 'FRCC'\n",
    "    counties.loc[counties['FIPS'] == 48007.0, 'Subregion'] = 'ERCT'\n",
    "    counties.loc[counties['FIPS'] == 53035.0, 'Subregion'] = 'NWPP'\n",
    "    counties.loc[counties['FIPS'] == 53029.0, 'Subregion'] = 'NWPP'\n",
    "    counties.loc[counties['FIPS'] == 51735.0, 'Subregion'] = 'SRVC'\n",
    "    counties.loc[counties['FIPS'] == 37137.0, 'Subregion'] = 'SRVC'\n",
    "    counties.loc[counties['FIPS'] == 37053.0, 'Subregion'] = 'SRVC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll round the LON and LAT values to the nearest quarter degree to faciliate future merges with ERA5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each file in counties_files, round LON and LAT to the nearest quarter-degree and re-compute the centroid from these values\n",
    "for counties in counties_files:\n",
    "    counties['LON'] = (counties['LON'] * 4).round() / 4\n",
    "    counties['LAT'] = (counties['LAT'] * 4).round() / 4\n",
    "    counties['centroid'] = geopandas.points_from_xy(counties['LON'], counties['LAT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the NRI data and merge it with the counties_within data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data file ../Data/NRI_Table_Counties.csv\n",
    "nri_2023 = pd.read_csv('../Data/NRI_Table_Counties_2023/NRI_Table_Counties.csv')\n",
    "nri_2021 = pd.read_csv('../Data/NRI_Table_Counties_2021/NRI_Table_Counties.csv')\n",
    "nri_2020 = pd.read_csv('../Data/NRI_Table_Counties_2020/NRI_Table_Counties.csv')\n",
    "\n",
    "#Restrict the nri dataset to only the variables in NRI_Features\n",
    "NRI_Features = ['STCOFIPS', 'POPULATION', 'BUILDVALUE','AGRIVALUE','AREA','SOVI_SCORE','AVLN_RISKS','CFLD_RISKS','CWAV_RISKS','HAIL_RISKS','HWAV_RISKS','HRCN_RISKS','ISTM_RISKS','LNDS_RISKS','LTNG_RISKS','RFLD_RISKS','SWND_RISKS','TRND_RISKS','TSUN_RISKS','WFIR_RISKS','WNTW_RISKS']\n",
    "nri_2023 = nri_2023[NRI_Features]\n",
    "nri_2021 = nri_2021[NRI_Features]\n",
    "nri_2020 = nri_2020[NRI_Features]\n",
    "\n",
    "#Merge counties and nri based on the FIPS (in counties) and COUNTYFIPS (in nri) variables\n",
    "counties2023_nri = counties2023.merge(nri_2023, left_on='FIPS', right_on='STCOFIPS', how='left')\n",
    "counties2022_nri = counties2022.merge(nri_2021, left_on='FIPS', right_on='STCOFIPS', how='left')\n",
    "counties2021_nri = counties2021.merge(nri_2021, left_on='FIPS', right_on='STCOFIPS', how='left')\n",
    "counties2020_nri = counties2020.merge(nri_2020, left_on='FIPS', right_on='STCOFIPS', how='left')\n",
    "counties2019_nri = counties2019.merge(nri_2020, left_on='FIPS', right_on='STCOFIPS', how='left')\n",
    "counties2018_nri = counties2018.merge(nri_2020, left_on='FIPS', right_on='STCOFIPS', how='left')\n",
    "counties2017_nri = counties2017.merge(nri_2020, left_on='FIPS', right_on='STCOFIPS', how='left')\n",
    "counties2016_nri = counties2016.merge(nri_2020, left_on='FIPS', right_on='STCOFIPS', how='left')\n",
    "counties2015_nri = counties2015.merge(nri_2020, left_on='FIPS', right_on='STCOFIPS', how='left')\n",
    "counties2014_nri = counties2014.merge(nri_2020, left_on='FIPS', right_on='STCOFIPS', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the empower data, take averages over the course of each year, and do some cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset ../Data/Empower_csvs/2023_HHSemPOWERMapHistoricalDataset.csv\n",
    "empower2023 = pd.read_csv('../Data/Empower_csvs/2023_HHSemPOWERMapHistoricalDataset.csv')\n",
    "empower2022 = pd.read_csv('../Data/Empower_csvs/2022_HHSemPOWERMapHistoricalDataset.csv')\n",
    "empower2021 = pd.read_csv('../Data/Empower_csvs/2021_HHSemPOWERMapHistoricalDataset.csv')\n",
    "empower2020 = pd.read_csv('../Data/Empower_csvs/2020_HHSemPOWERMapHistoricalDataset.csv')\n",
    "empower2019 = pd.read_csv('../Data/Empower_csvs/2019_HHSemPOWERMapHistoricalDataset.csv')\n",
    "empower2018 = pd.read_csv('../Data/Empower_csvs/2018_HHSemPOWERMapHistoricalDataset.csv')\n",
    "empower2017 = pd.read_csv('../Data/Empower_csvs/2017_HHSemPOWERMapHistoricalDataset.csv')\n",
    "empower2016 = pd.read_csv('../Data/Empower_csvs/2016_HHSemPOWERMapHistoricalDataset.csv')\n",
    "\n",
    "empower_files = [empower2023, empower2022, empower2021, empower2020, empower2019, empower2018, empower2017, empower2016]\n",
    "\n",
    "for df in empower_files:\n",
    "    #Create a list of features we won't need (including all variables with \"Medicare_Benes\" in their name). Then drop these columns\n",
    "    nonfeatures = ['County_FIPS_Code', 'County','State_FIPS_Code', 'State']\n",
    "    nonfeatures.extend([col for col in df.columns if 'Medicare_Benes' in col])\n",
    "    df.drop(columns=[col for col in df.columns if col in nonfeatures], inplace=True)\n",
    "\n",
    "    #For each column in df that is an object, remove commas\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].str.replace(',', '')\n",
    "\n",
    "    #For each column in df, convert to an integer\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    #Append a new column computed by taking the mean of all columns with \"Power_Dependent_Devices_DME\" in their name\n",
    "    df['Power_Dependent_Devices_DME_Mean'] = df[[col for col in df.columns if 'Power_Dependent_Devices_DME' in col]].mean(axis=1)\n",
    "\n",
    "    #Drop all variables except for FIPS_Code and Power_Dependent_Devices_DME_Mean\n",
    "    df.drop(columns=[col for col in df.columns if col not in ['FIPS_Code', 'Power_Dependent_Devices_DME_Mean']], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually merge the empower data with the counties_nri data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge counties[YEAR]_nri and empower[YEAR] based on the FIPS and FIPS_Code variables\n",
    "counties2023_nri_empower = counties2023_nri.merge(empower2023, left_on='FIPS', right_on='FIPS_Code', how='left')\n",
    "counties2022_nri_empower = counties2022_nri.merge(empower2022, left_on='FIPS', right_on='FIPS_Code', how='left')\n",
    "counties2021_nri_empower = counties2021_nri.merge(empower2021, left_on='FIPS', right_on='FIPS_Code', how='left')\n",
    "counties2020_nri_empower = counties2020_nri.merge(empower2020, left_on='FIPS', right_on='FIPS_Code', how='left')\n",
    "counties2019_nri_empower = counties2019_nri.merge(empower2019, left_on='FIPS', right_on='FIPS_Code', how='left')\n",
    "counties2018_nri_empower = counties2018_nri.merge(empower2018, left_on='FIPS', right_on='FIPS_Code', how='left')\n",
    "counties2017_nri_empower = counties2017_nri.merge(empower2017, left_on='FIPS', right_on='FIPS_Code', how='left')\n",
    "counties2016_nri_empower = counties2016_nri.merge(empower2016, left_on='FIPS', right_on='FIPS_Code', how='left')\n",
    "counties2015_nri_empower = counties2015_nri.merge(empower2016, left_on='FIPS', right_on='FIPS_Code', how='left')\n",
    "counties2014_nri_empower = counties2014_nri.merge(empower2016, left_on='FIPS', right_on='FIPS_Code', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a bit of cleaning and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list of countiesYEAR_nri_empower dataframes\n",
    "counties_nri_empower_files = [counties2023_nri_empower, counties2022_nri_empower, counties2021_nri_empower, counties2020_nri_empower, counties2019_nri_empower, counties2018_nri_empower, counties2017_nri_empower, counties2016_nri_empower, counties2015_nri_empower, counties2014_nri_empower]\n",
    "\n",
    "#Drop the variables LON, LAT, index_right, FIPS_Code, and STCOFIPS from counties_merged\n",
    "for counties in counties_nri_empower_files:\n",
    "    counties.drop(columns=['LON', 'LAT', 'index_right', 'FIPS_Code', 'STCOFIPS'], inplace=True)\n",
    "\n",
    "#Export each file as a csv\n",
    "for i, counties in enumerate(counties_nri_empower_files):\n",
    "    counties.to_csv(f'../Data/Counties_{2024-i}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
